{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Première analyse de application_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données :\n",
      "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
      "0      100002       1         Cash loans           M            N   \n",
      "1      100003       0         Cash loans           F            N   \n",
      "2      100004       0    Revolving loans           M            Y   \n",
      "3      100006       0         Cash loans           F            N   \n",
      "4      100007       0         Cash loans           M            N   \n",
      "\n",
      "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
      "0               Y             0          202500.0    406597.5      24700.5   \n",
      "1               N             0          270000.0   1293502.5      35698.5   \n",
      "2               Y             0           67500.0    135000.0       6750.0   \n",
      "3               Y             0          135000.0    312682.5      29686.5   \n",
      "4               Y             0          121500.0    513000.0      21865.5   \n",
      "\n",
      "   AMT_GOODS_PRICE NAME_TYPE_SUITE NAME_INCOME_TYPE  \\\n",
      "0         351000.0   Unaccompanied          Working   \n",
      "1        1129500.0          Family    State servant   \n",
      "2         135000.0   Unaccompanied          Working   \n",
      "3         297000.0   Unaccompanied          Working   \n",
      "4         513000.0   Unaccompanied          Working   \n",
      "\n",
      "             NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  \\\n",
      "0  Secondary / secondary special  Single / not married  House / apartment   \n",
      "1               Higher education               Married  House / apartment   \n",
      "2  Secondary / secondary special  Single / not married  House / apartment   \n",
      "3  Secondary / secondary special        Civil marriage  House / apartment   \n",
      "4  Secondary / secondary special  Single / not married  House / apartment   \n",
      "\n",
      "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  \\\n",
      "0                    0.018801       -9461           -637            -3648.0   \n",
      "1                    0.003541      -16765          -1188            -1186.0   \n",
      "2                    0.010032      -19046           -225            -4260.0   \n",
      "3                    0.008019      -19005          -3039            -9833.0   \n",
      "4                    0.028663      -19932          -3038            -4311.0   \n",
      "\n",
      "   DAYS_ID_PUBLISH  OWN_CAR_AGE  FLAG_MOBIL  FLAG_EMP_PHONE  FLAG_WORK_PHONE  \\\n",
      "0            -2120          NaN           1               1                0   \n",
      "1             -291          NaN           1               1                0   \n",
      "2            -2531         26.0           1               1                1   \n",
      "3            -2437          NaN           1               1                0   \n",
      "4            -3458          NaN           1               1                0   \n",
      "\n",
      "   FLAG_CONT_MOBILE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  CNT_FAM_MEMBERS  \\\n",
      "0                 1           1           0        Laborers              1.0   \n",
      "1                 1           1           0      Core staff              2.0   \n",
      "2                 1           1           0        Laborers              1.0   \n",
      "3                 1           0           0        Laborers              2.0   \n",
      "4                 1           0           0      Core staff              1.0   \n",
      "\n",
      "   REGION_RATING_CLIENT  REGION_RATING_CLIENT_W_CITY  \\\n",
      "0                     2                            2   \n",
      "1                     1                            1   \n",
      "2                     2                            2   \n",
      "3                     2                            2   \n",
      "4                     2                            2   \n",
      "\n",
      "  WEEKDAY_APPR_PROCESS_START  HOUR_APPR_PROCESS_START  \\\n",
      "0                  WEDNESDAY                       10   \n",
      "1                     MONDAY                       11   \n",
      "2                     MONDAY                        9   \n",
      "3                  WEDNESDAY                       17   \n",
      "4                   THURSDAY                       11   \n",
      "\n",
      "   REG_REGION_NOT_LIVE_REGION  REG_REGION_NOT_WORK_REGION  \\\n",
      "0                           0                           0   \n",
      "1                           0                           0   \n",
      "2                           0                           0   \n",
      "3                           0                           0   \n",
      "4                           0                           0   \n",
      "\n",
      "   LIVE_REGION_NOT_WORK_REGION  REG_CITY_NOT_LIVE_CITY  \\\n",
      "0                            0                       0   \n",
      "1                            0                       0   \n",
      "2                            0                       0   \n",
      "3                            0                       0   \n",
      "4                            0                       0   \n",
      "\n",
      "   REG_CITY_NOT_WORK_CITY  LIVE_CITY_NOT_WORK_CITY       ORGANIZATION_TYPE  \\\n",
      "0                       0                        0  Business Entity Type 3   \n",
      "1                       0                        0                  School   \n",
      "2                       0                        0              Government   \n",
      "3                       0                        0  Business Entity Type 3   \n",
      "4                       1                        1                Religion   \n",
      "\n",
      "   EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  APARTMENTS_AVG  BASEMENTAREA_AVG  \\\n",
      "0      0.083037      0.262949      0.139376          0.0247            0.0369   \n",
      "1      0.311267      0.622246           NaN          0.0959            0.0529   \n",
      "2           NaN      0.555912      0.729567             NaN               NaN   \n",
      "3           NaN      0.650442           NaN             NaN               NaN   \n",
      "4           NaN      0.322738           NaN             NaN               NaN   \n",
      "\n",
      "   YEARS_BEGINEXPLUATATION_AVG  YEARS_BUILD_AVG  COMMONAREA_AVG  \\\n",
      "0                       0.9722           0.6192          0.0143   \n",
      "1                       0.9851           0.7960          0.0605   \n",
      "2                          NaN              NaN             NaN   \n",
      "3                          NaN              NaN             NaN   \n",
      "4                          NaN              NaN             NaN   \n",
      "\n",
      "   ELEVATORS_AVG  ENTRANCES_AVG  FLOORSMAX_AVG  FLOORSMIN_AVG  LANDAREA_AVG  \\\n",
      "0           0.00         0.0690         0.0833         0.1250        0.0369   \n",
      "1           0.08         0.0345         0.2917         0.3333        0.0130   \n",
      "2            NaN            NaN            NaN            NaN           NaN   \n",
      "3            NaN            NaN            NaN            NaN           NaN   \n",
      "4            NaN            NaN            NaN            NaN           NaN   \n",
      "\n",
      "   LIVINGAPARTMENTS_AVG  LIVINGAREA_AVG  NONLIVINGAPARTMENTS_AVG  \\\n",
      "0                0.0202          0.0190                   0.0000   \n",
      "1                0.0773          0.0549                   0.0039   \n",
      "2                   NaN             NaN                      NaN   \n",
      "3                   NaN             NaN                      NaN   \n",
      "4                   NaN             NaN                      NaN   \n",
      "\n",
      "   NONLIVINGAREA_AVG  APARTMENTS_MODE  BASEMENTAREA_MODE  \\\n",
      "0             0.0000           0.0252             0.0383   \n",
      "1             0.0098           0.0924             0.0538   \n",
      "2                NaN              NaN                NaN   \n",
      "3                NaN              NaN                NaN   \n",
      "4                NaN              NaN                NaN   \n",
      "\n",
      "   YEARS_BEGINEXPLUATATION_MODE  YEARS_BUILD_MODE  COMMONAREA_MODE  \\\n",
      "0                        0.9722            0.6341           0.0144   \n",
      "1                        0.9851            0.8040           0.0497   \n",
      "2                           NaN               NaN              NaN   \n",
      "3                           NaN               NaN              NaN   \n",
      "4                           NaN               NaN              NaN   \n",
      "\n",
      "   ELEVATORS_MODE  ENTRANCES_MODE  FLOORSMAX_MODE  FLOORSMIN_MODE  \\\n",
      "0          0.0000          0.0690          0.0833          0.1250   \n",
      "1          0.0806          0.0345          0.2917          0.3333   \n",
      "2             NaN             NaN             NaN             NaN   \n",
      "3             NaN             NaN             NaN             NaN   \n",
      "4             NaN             NaN             NaN             NaN   \n",
      "\n",
      "   LANDAREA_MODE  LIVINGAPARTMENTS_MODE  LIVINGAREA_MODE  \\\n",
      "0         0.0377                  0.022           0.0198   \n",
      "1         0.0128                  0.079           0.0554   \n",
      "2            NaN                    NaN              NaN   \n",
      "3            NaN                    NaN              NaN   \n",
      "4            NaN                    NaN              NaN   \n",
      "\n",
      "   NONLIVINGAPARTMENTS_MODE  NONLIVINGAREA_MODE  APARTMENTS_MEDI  \\\n",
      "0                       0.0                 0.0           0.0250   \n",
      "1                       0.0                 0.0           0.0968   \n",
      "2                       NaN                 NaN              NaN   \n",
      "3                       NaN                 NaN              NaN   \n",
      "4                       NaN                 NaN              NaN   \n",
      "\n",
      "   BASEMENTAREA_MEDI  YEARS_BEGINEXPLUATATION_MEDI  YEARS_BUILD_MEDI  \\\n",
      "0             0.0369                        0.9722            0.6243   \n",
      "1             0.0529                        0.9851            0.7987   \n",
      "2                NaN                           NaN               NaN   \n",
      "3                NaN                           NaN               NaN   \n",
      "4                NaN                           NaN               NaN   \n",
      "\n",
      "   COMMONAREA_MEDI  ELEVATORS_MEDI  ENTRANCES_MEDI  FLOORSMAX_MEDI  \\\n",
      "0           0.0144            0.00          0.0690          0.0833   \n",
      "1           0.0608            0.08          0.0345          0.2917   \n",
      "2              NaN             NaN             NaN             NaN   \n",
      "3              NaN             NaN             NaN             NaN   \n",
      "4              NaN             NaN             NaN             NaN   \n",
      "\n",
      "   FLOORSMIN_MEDI  LANDAREA_MEDI  LIVINGAPARTMENTS_MEDI  LIVINGAREA_MEDI  \\\n",
      "0          0.1250         0.0375                 0.0205           0.0193   \n",
      "1          0.3333         0.0132                 0.0787           0.0558   \n",
      "2             NaN            NaN                    NaN              NaN   \n",
      "3             NaN            NaN                    NaN              NaN   \n",
      "4             NaN            NaN                    NaN              NaN   \n",
      "\n",
      "   NONLIVINGAPARTMENTS_MEDI  NONLIVINGAREA_MEDI FONDKAPREMONT_MODE  \\\n",
      "0                    0.0000                0.00   reg oper account   \n",
      "1                    0.0039                0.01   reg oper account   \n",
      "2                       NaN                 NaN                NaN   \n",
      "3                       NaN                 NaN                NaN   \n",
      "4                       NaN                 NaN                NaN   \n",
      "\n",
      "   HOUSETYPE_MODE  TOTALAREA_MODE WALLSMATERIAL_MODE EMERGENCYSTATE_MODE  \\\n",
      "0  block of flats          0.0149       Stone, brick                  No   \n",
      "1  block of flats          0.0714              Block                  No   \n",
      "2             NaN             NaN                NaN                 NaN   \n",
      "3             NaN             NaN                NaN                 NaN   \n",
      "4             NaN             NaN                NaN                 NaN   \n",
      "\n",
      "   OBS_30_CNT_SOCIAL_CIRCLE  DEF_30_CNT_SOCIAL_CIRCLE  \\\n",
      "0                       2.0                       2.0   \n",
      "1                       1.0                       0.0   \n",
      "2                       0.0                       0.0   \n",
      "3                       2.0                       0.0   \n",
      "4                       0.0                       0.0   \n",
      "\n",
      "   OBS_60_CNT_SOCIAL_CIRCLE  DEF_60_CNT_SOCIAL_CIRCLE  DAYS_LAST_PHONE_CHANGE  \\\n",
      "0                       2.0                       2.0                 -1134.0   \n",
      "1                       1.0                       0.0                  -828.0   \n",
      "2                       0.0                       0.0                  -815.0   \n",
      "3                       2.0                       0.0                  -617.0   \n",
      "4                       0.0                       0.0                 -1106.0   \n",
      "\n",
      "   FLAG_DOCUMENT_2  FLAG_DOCUMENT_3  FLAG_DOCUMENT_4  FLAG_DOCUMENT_5  \\\n",
      "0                0                1                0                0   \n",
      "1                0                1                0                0   \n",
      "2                0                0                0                0   \n",
      "3                0                1                0                0   \n",
      "4                0                0                0                0   \n",
      "\n",
      "   FLAG_DOCUMENT_6  FLAG_DOCUMENT_7  FLAG_DOCUMENT_8  FLAG_DOCUMENT_9  \\\n",
      "0                0                0                0                0   \n",
      "1                0                0                0                0   \n",
      "2                0                0                0                0   \n",
      "3                0                0                0                0   \n",
      "4                0                0                1                0   \n",
      "\n",
      "   FLAG_DOCUMENT_10  FLAG_DOCUMENT_11  FLAG_DOCUMENT_12  FLAG_DOCUMENT_13  \\\n",
      "0                 0                 0                 0                 0   \n",
      "1                 0                 0                 0                 0   \n",
      "2                 0                 0                 0                 0   \n",
      "3                 0                 0                 0                 0   \n",
      "4                 0                 0                 0                 0   \n",
      "\n",
      "   FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  FLAG_DOCUMENT_17  \\\n",
      "0                 0                 0                 0                 0   \n",
      "1                 0                 0                 0                 0   \n",
      "2                 0                 0                 0                 0   \n",
      "3                 0                 0                 0                 0   \n",
      "4                 0                 0                 0                 0   \n",
      "\n",
      "   FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  \\\n",
      "0                 0                 0                 0                 0   \n",
      "1                 0                 0                 0                 0   \n",
      "2                 0                 0                 0                 0   \n",
      "3                 0                 0                 0                 0   \n",
      "4                 0                 0                 0                 0   \n",
      "\n",
      "   AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
      "0                         0.0                        0.0   \n",
      "1                         0.0                        0.0   \n",
      "2                         0.0                        0.0   \n",
      "3                         NaN                        NaN   \n",
      "4                         0.0                        0.0   \n",
      "\n",
      "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
      "0                         0.0                        0.0   \n",
      "1                         0.0                        0.0   \n",
      "2                         0.0                        0.0   \n",
      "3                         NaN                        NaN   \n",
      "4                         0.0                        0.0   \n",
      "\n",
      "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
      "0                        0.0                         1.0  \n",
      "1                        0.0                         0.0  \n",
      "2                        0.0                         0.0  \n",
      "3                        NaN                         NaN  \n",
      "4                        0.0                         0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv(\"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/application_train.csv\")\n",
    "\n",
    "# Afficher les premières lignes\n",
    "print(\"Aperçu des données :\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valeurs manquantes :\n",
      "SK_ID_CURR                        0\n",
      "TARGET                            0\n",
      "NAME_CONTRACT_TYPE                0\n",
      "CODE_GENDER                       0\n",
      "FLAG_OWN_CAR                      0\n",
      "                              ...  \n",
      "AMT_REQ_CREDIT_BUREAU_DAY     41519\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK    41519\n",
      "AMT_REQ_CREDIT_BUREAU_MON     41519\n",
      "AMT_REQ_CREDIT_BUREAU_QRT     41519\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR    41519\n",
      "Length: 122, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Vérifier les valeurs manquantes\n",
    "print(\"\\nValeurs manquantes :\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informations sur les colonnes :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 122 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "dtypes: float64(65), int64(41), object(16)\n",
      "memory usage: 286.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Infos générales\n",
    "print(\"\\nInformations sur les colonnes :\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution de la variable cible :\n",
      "TARGET\n",
      "0    0.919271\n",
      "1    0.080729\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Vérifier la distribution de la variable cible (TARGET)\n",
    "print(\"\\nDistribution de la variable cible :\")\n",
    "print(df[\"TARGET\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde les colonnes avec des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes avec des valeurs manquantes :\n",
      "COMMONAREA_MEDI             214865\n",
      "COMMONAREA_AVG              214865\n",
      "COMMONAREA_MODE             214865\n",
      "NONLIVINGAPARTMENTS_MEDI    213514\n",
      "NONLIVINGAPARTMENTS_MODE    213514\n",
      "                             ...  \n",
      "EXT_SOURCE_2                   660\n",
      "AMT_GOODS_PRICE                278\n",
      "AMT_ANNUITY                     12\n",
      "CNT_FAM_MEMBERS                  2\n",
      "DAYS_LAST_PHONE_CHANGE           1\n",
      "Length: 67, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Désactiver la troncature automatique des colonnes\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]  # On garde les colonnes avec des NaN\n",
    "missing_values = missing_values.sort_values(ascending=False)\n",
    "\n",
    "print(\"Colonnes avec des valeurs manquantes :\")\n",
    "print(missing_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes supprimées :\n",
      "Index(['OWN_CAR_AGE', 'OCCUPATION_TYPE', 'EXT_SOURCE_1', 'APARTMENTS_AVG',\n",
      "       'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG',\n",
      "       'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG',\n",
      "       'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG',\n",
      "       'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG',\n",
      "       'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE',\n",
      "       'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE',\n",
      "       'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE',\n",
      "       'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE',\n",
      "       'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI',\n",
      "       'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI',\n",
      "       'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI',\n",
      "       'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI',\n",
      "       'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'FONDKAPREMONT_MODE',\n",
      "       'HOUSETYPE_MODE', 'TOTALAREA_MODE', 'WALLSMATERIAL_MODE',\n",
      "       'EMERGENCYSTATE_MODE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Définir un seuil de valeurs manquantes (par exemple, une colonne avec plus de 30% de NaN sera supprimée)\n",
    "seuil_na = 0.3  # 30% de valeurs manquantes\n",
    "\n",
    "# Calculer le nombre total de NaN par colonne\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Calculer le pourcentage de valeurs manquantes\n",
    "missing_percentage = missing_values / len(df)\n",
    "\n",
    "# Sélectionner les colonnes où le pourcentage de NaN est supérieur au seuil\n",
    "columns_to_drop = missing_percentage[missing_percentage > seuil_na].index\n",
    "\n",
    "# Supprimer ces colonnes\n",
    "df_cleaned = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Afficher les colonnes supprimées\n",
    "print(\"Colonnes supprimées :\")\n",
    "print(columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes restantes avec des NaN :\n",
      "AMT_ANNUITY                      12\n",
      "AMT_GOODS_PRICE                 278\n",
      "NAME_TYPE_SUITE                1292\n",
      "CNT_FAM_MEMBERS                   2\n",
      "EXT_SOURCE_2                    660\n",
      "EXT_SOURCE_3                  60965\n",
      "OBS_30_CNT_SOCIAL_CIRCLE       1021\n",
      "DEF_30_CNT_SOCIAL_CIRCLE       1021\n",
      "OBS_60_CNT_SOCIAL_CIRCLE       1021\n",
      "DEF_60_CNT_SOCIAL_CIRCLE       1021\n",
      "DAYS_LAST_PHONE_CHANGE            1\n",
      "AMT_REQ_CREDIT_BUREAU_HOUR    41519\n",
      "AMT_REQ_CREDIT_BUREAU_DAY     41519\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK    41519\n",
      "AMT_REQ_CREDIT_BUREAU_MON     41519\n",
      "AMT_REQ_CREDIT_BUREAU_QRT     41519\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR    41519\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Vérifier s'il reste des NaN dans le DataFrame nettoyé\n",
    "missing_values_after = df_cleaned.isnull().sum()\n",
    "print(\"Colonnes restantes avec des NaN :\")\n",
    "print(missing_values_after[missing_values_after > 0])  # Affiche les NaN restantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes restantes avec des NaN après remplissage :\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Remplir les colonnes numériques avec la moyenne\n",
    "numerical_columns = df_cleaned.select_dtypes(include=['float64', 'int64']).columns  # Sélectionner les colonnes numériques\n",
    "df_cleaned[numerical_columns] = df_cleaned[numerical_columns].fillna(df_cleaned[numerical_columns].mean())\n",
    "\n",
    "# Remplir les colonnes catégorielles avec la modalité la plus fréquente (mode)\n",
    "categorical_columns = df_cleaned.select_dtypes(include=['object']).columns  # Sélectionner les colonnes catégorielles\n",
    "for col in categorical_columns:\n",
    "    df_cleaned[col] = df_cleaned[col].fillna(df_cleaned[col].mode()[0])\n",
    "\n",
    "# Vérifier si toutes les valeurs manquantes sont traitées\n",
    "missing_values_after = df_cleaned.isnull().sum()\n",
    "print(\"Colonnes restantes avec des NaN après remplissage :\")\n",
    "print(missing_values_after[missing_values_after > 0])  # Affiche les NaN restantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données :\n",
      "   SK_ID_BUREAU  MONTHS_BALANCE STATUS\n",
      "0       5715448               0      C\n",
      "1       5715448              -1      C\n",
      "2       5715448              -2      C\n",
      "3       5715448              -3      C\n",
      "4       5715448              -4      C\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv(\"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/bureau_balance.csv\")\n",
    "\n",
    "# Afficher les premières lignes\n",
    "print(\"Aperçu des données :\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données :\n",
      "   SK_ID_CURR  SK_ID_BUREAU CREDIT_ACTIVE CREDIT_CURRENCY  DAYS_CREDIT  \\\n",
      "0      215354       5714462        Closed      currency 1         -497   \n",
      "1      215354       5714463        Active      currency 1         -208   \n",
      "2      215354       5714464        Active      currency 1         -203   \n",
      "3      215354       5714465        Active      currency 1         -203   \n",
      "4      215354       5714466        Active      currency 1         -629   \n",
      "\n",
      "   CREDIT_DAY_OVERDUE  DAYS_CREDIT_ENDDATE  DAYS_ENDDATE_FACT  \\\n",
      "0                   0               -153.0             -153.0   \n",
      "1                   0               1075.0                NaN   \n",
      "2                   0                528.0                NaN   \n",
      "3                   0                  NaN                NaN   \n",
      "4                   0               1197.0                NaN   \n",
      "\n",
      "   AMT_CREDIT_MAX_OVERDUE  CNT_CREDIT_PROLONG  AMT_CREDIT_SUM  \\\n",
      "0                     NaN                   0         91323.0   \n",
      "1                     NaN                   0        225000.0   \n",
      "2                     NaN                   0        464323.5   \n",
      "3                     NaN                   0         90000.0   \n",
      "4                 77674.5                   0       2700000.0   \n",
      "\n",
      "   AMT_CREDIT_SUM_DEBT  AMT_CREDIT_SUM_LIMIT  AMT_CREDIT_SUM_OVERDUE  \\\n",
      "0                  0.0                   NaN                     0.0   \n",
      "1             171342.0                   NaN                     0.0   \n",
      "2                  NaN                   NaN                     0.0   \n",
      "3                  NaN                   NaN                     0.0   \n",
      "4                  NaN                   NaN                     0.0   \n",
      "\n",
      "       CREDIT_TYPE  DAYS_CREDIT_UPDATE  AMT_ANNUITY  \n",
      "0  Consumer credit                -131          NaN  \n",
      "1      Credit card                 -20          NaN  \n",
      "2  Consumer credit                 -16          NaN  \n",
      "3      Credit card                 -16          NaN  \n",
      "4  Consumer credit                 -21          NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv(\"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/bureau.csv\")\n",
    "\n",
    "# Afficher les premières lignes\n",
    "print(\"Aperçu des données :\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On nettoie Bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs manquantes restantes :\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1️⃣ Charger les données\n",
    "bureau = pd.read_csv(\"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/bureau.csv\")\n",
    "\n",
    "# 2️⃣ Supprimer les colonnes avec plus de 30% de valeurs manquantes\n",
    "missing_ratio = bureau.isna().mean()  # Ratio de valeurs manquantes par colonne\n",
    "columns_to_drop = missing_ratio[missing_ratio > 0.3].index  # Colonnes à supprimer\n",
    "bureau_cleaned = bureau.drop(columns=columns_to_drop)\n",
    "\n",
    "# 3️⃣ Compléter les valeurs manquantes\n",
    "# Séparer les colonnes numériques et catégoriques\n",
    "num_cols = bureau_cleaned.select_dtypes(include=[\"number\"]).columns\n",
    "cat_cols = bureau_cleaned.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Remplacer les NaN des colonnes numériques par la moyenne\n",
    "bureau_cleaned[num_cols] = bureau_cleaned[num_cols].fillna(bureau_cleaned[num_cols].mean())\n",
    "\n",
    "# Remplacer les NaN des colonnes catégoriques par la valeur la plus fréquente (mode)\n",
    "for col in cat_cols:\n",
    "    bureau_cleaned[col] = bureau_cleaned[col].fillna(bureau_cleaned[col].mode()[0])\n",
    "\n",
    "# 4️⃣ Vérifier qu'il ne reste plus de valeurs manquantes\n",
    "print(\"Valeurs manquantes restantes :\")\n",
    "print(bureau_cleaned.isna().sum().sum())  # Doit afficher 0 si tout est bien rempli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On encode les variables catégoriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes catégoriques :  ['CREDIT_ACTIVE', 'CREDIT_CURRENCY', 'CREDIT_TYPE']\n",
      "Nombre de valeurs distinctes par colonne : \n",
      "CREDIT_ACTIVE: 4\n",
      "CREDIT_CURRENCY: 4\n",
      "CREDIT_TYPE: 15\n"
     ]
    }
   ],
   "source": [
    "# Identifier les colonnes catégoriques\n",
    "categorical_cols = bureau_cleaned.select_dtypes(include=['object']).columns\n",
    "print(\"Colonnes catégoriques : \", categorical_cols.tolist())\n",
    "\n",
    "# Compter le nombre de valeurs distinctes pour chaque colonne catégorique\n",
    "category_counts = {col: bureau_cleaned[col].nunique() for col in categorical_cols}\n",
    "\n",
    "# Afficher le nombre de valeurs distinctes par colonne\n",
    "print(\"Nombre de valeurs distinctes par colonne : \")\n",
    "for col, count in category_counts.items():\n",
    "    print(f\"{col}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes catégoriques :  ['CREDIT_ACTIVE', 'CREDIT_CURRENCY', 'CREDIT_TYPE']\n",
      "Nombre de catégories par colonne :  {'CREDIT_ACTIVE': 4, 'CREDIT_CURRENCY': 4, 'CREDIT_TYPE': 15}\n",
      "Nouvelles colonnes après encodage :  ['SK_ID_CURR', 'SK_ID_BUREAU', 'DAYS_CREDIT', 'CREDIT_DAY_OVERDUE', 'DAYS_CREDIT_ENDDATE', 'CNT_CREDIT_PROLONG', 'AMT_CREDIT_SUM', 'AMT_CREDIT_SUM_DEBT', 'AMT_CREDIT_SUM_OVERDUE', 'DAYS_CREDIT_UPDATE', 'CREDIT_ACTIVE_Active', 'CREDIT_ACTIVE_Bad debt', 'CREDIT_ACTIVE_Closed', 'CREDIT_ACTIVE_Sold', 'CREDIT_CURRENCY_currency 1', 'CREDIT_CURRENCY_currency 2', 'CREDIT_CURRENCY_currency 3', 'CREDIT_CURRENCY_currency 4', 'CREDIT_TYPE_Another type of loan', 'CREDIT_TYPE_Car loan', 'CREDIT_TYPE_Cash loan (non-earmarked)', 'CREDIT_TYPE_Consumer credit', 'CREDIT_TYPE_Credit card', 'CREDIT_TYPE_Interbank credit', 'CREDIT_TYPE_Loan for business development', 'CREDIT_TYPE_Loan for purchase of shares (margin lending)', 'CREDIT_TYPE_Loan for the purchase of equipment', 'CREDIT_TYPE_Loan for working capital replenishment', 'CREDIT_TYPE_Microloan', 'CREDIT_TYPE_Mobile operator loan', 'CREDIT_TYPE_Mortgage', 'CREDIT_TYPE_Real estate loan', 'CREDIT_TYPE_Unknown type of loan']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identifier les colonnes catégoriques\n",
    "categorical_cols = bureau_cleaned.select_dtypes(include=['object']).columns\n",
    "print(\"Colonnes catégoriques : \", categorical_cols.tolist())\n",
    "\n",
    "# Vérifier le nombre de catégories par colonne\n",
    "category_counts = {col: bureau_cleaned[col].nunique() for col in categorical_cols}\n",
    "print(\"Nombre de catégories par colonne : \", category_counts)\n",
    "\n",
    "# Appliquer One-Hot Encoding si <= 15 catégories, sinon Label Encoding\n",
    "for col in categorical_cols:\n",
    "    if category_counts[col] <= 15:\n",
    "        # One-Hot Encoding\n",
    "        bureau_cleaned = pd.get_dummies(bureau_cleaned, columns=[col], prefix=col)\n",
    "    else:\n",
    "        # Label Encoding\n",
    "        le = LabelEncoder()\n",
    "        bureau_cleaned[col] = le.fit_transform(bureau_cleaned[col])\n",
    "\n",
    "# Vérification\n",
    "print(\"Nouvelles colonnes après encodage : \", bureau_cleaned.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Charger les données\n",
    "application_train = pd.read_csv(\"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/application_train.csv\")\n",
    "\n",
    "# Joindre bureau_cleaned avec le target à partir de application_train\n",
    "df_rf = bureau_cleaned.merge(application_train[[\"SK_ID_CURR\", \"TARGET\"]], on=\"SK_ID_CURR\", how=\"left\")\n",
    "df_rf = df_rf.dropna(subset=[\"TARGET\"])  # Supprimer les lignes où TARGET est manquant\n",
    "\n",
    "# Séparer les features et la target\n",
    "X = df_rf.drop(columns=[\"SK_ID_CURR\", \"TARGET\"])\n",
    "y = df_rf[\"TARGET\"]\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Appliquer le Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Récupérer l'importance des features\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"importance\": rf.feature_importances_\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "# Affichage du graphique d'importance des features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=feature_importance.head(20))  # Afficher les top 20 features\n",
    "plt.title(\"Top 20 des Features les Plus Importants (Random Forest)\", fontsize=16)\n",
    "plt.xlabel(\"Importance\", fontsize=12)\n",
    "plt.ylabel(\"Feature\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier CSV 'top_6_features.csv' enregistré avec succès !\n"
     ]
    }
   ],
   "source": [
    "# Garder uniquement les 6 meilleures features\n",
    "top_6_features = feature_importance.head(6)[\"feature\"].tolist()\n",
    "\n",
    "# Filtrer le DataFrame avec ces features\n",
    "df_top_6 = df_rf[[\"SK_ID_CURR\"] + top_6_features]  # Garder aussi SK_ID_CURR pour référence\n",
    "\n",
    "# Enregistrer en CSV\n",
    "df_top_6.to_csv(\"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/top_6_features.csv\", index=False)\n",
    "\n",
    "print(\"Fichier CSV 'top_6_features.csv' enregistré avec succès !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bureau_balance \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/bureau_balance.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Mapping des statuts pour pondérer les retards\u001b[39;00m\n\u001b[1;32m      3\u001b[0m status_mapping \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "bureau_balance = pd.read_csv(\"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/bureau_balance.csv\")\n",
    "# Mapping des statuts pour pondérer les retards\n",
    "status_mapping = {'0': 0, 'C': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}\n",
    "\n",
    "# Appliquer le mapping\n",
    "bureau_balance[\"STATUS_SCORE\"] = bureau_balance[\"STATUS\"].map(status_mapping).fillna(0)\n",
    "\n",
    "# Agréger par SK_ID_BUREAU\n",
    "bureau_agg = bureau_balance.groupby(\"SK_ID_BUREAU\").agg(\n",
    "    total_months=(\"MONTHS_BALANCE\", \"count\"),  # Nombre total de mois enregistrés\n",
    "    unpaid_months=(\"STATUS_SCORE\", lambda x: (x > 0).sum()),  # Nombre de mois avec impayés\n",
    "    max_delay=(\"STATUS_SCORE\", \"max\"),  # Plus grand retard enregistré\n",
    "    avg_delay=(\"STATUS_SCORE\", \"mean\")  # Retard moyen sur toute la durée\n",
    ").reset_index()\n",
    "\n",
    "# Calculer le ratio d'impayés\n",
    "bureau_agg[\"unpaid_ratio\"] = bureau_agg[\"unpaid_months\"] / bureau_agg[\"total_months\"]\n",
    "\n",
    "# Supprimer les colonnes inutiles\n",
    "bureau_agg.drop(columns=[\"unpaid_months\", \"total_months\"], inplace=True)\n",
    "\n",
    "# Fusion avec bureau.csv\n",
    "bureau_merged = df_top_6.merge(bureau_agg, on=\"SK_ID_BUREAU\", how=\"left\")\n",
    "\n",
    "# Enregistrer le fichier final\n",
    "bureau_merged.to_csv(\"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/merged_top_6_bureau_and_balance.csv\", index=False)\n",
    "\n",
    "print(\"Fichier fusionné enregistré sous 'merged_top_6_bureau_and_balance.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK_ID_CURR                  0\n",
      "SK_ID_BUREAU                0\n",
      "DAYS_CREDIT                 0\n",
      "DAYS_CREDIT_ENDDATE         0\n",
      "DAYS_CREDIT_UPDATE          0\n",
      "AMT_CREDIT_SUM              0\n",
      "AMT_CREDIT_SUM_DEBT         0\n",
      "max_delay              941810\n",
      "avg_delay              941810\n",
      "unpaid_ratio           941810\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(bureau_merged.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remplit les colonnes manquantes par des 0 car on suppose que si ils ne sont pas suivi dans bureau balance, il n'y a logiquement pas eu de retard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bureau_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Remplacer NaN par 0 pour les colonnes de retard\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mbureau_merged\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_delay\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m bureau_merged[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_delay\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m bureau_merged[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munpaid_ratio\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bureau_merged' is not defined"
     ]
    }
   ],
   "source": [
    "# Remplacer NaN par 0 pour les colonnes de retard\n",
    "bureau_merged[\"max_delay\"].fillna(0, inplace=True)\n",
    "bureau_merged[\"avg_delay\"].fillna(0, inplace=True)\n",
    "bureau_merged[\"unpaid_ratio\"].fillna(0, inplace=True)\n",
    "\n",
    "# Enregistrer le fichier final\n",
    "bureau_merged.to_csv(\"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/merged_top_6_bureau_and_balance.csv\", index=False)\n",
    "\n",
    "print(\"Correction appliquée : valeurs NaN remplacées par 0 et fichier enregistré ! ✅\")\n",
    "print(bureau_merged.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regroupe tous les prêts par individu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regroupement terminé et fichier enregistré ! ✅\n"
     ]
    }
   ],
   "source": [
    "bureau_merged =  pd.read_csv(\"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/merged_top_6_bureau_and_balance.csv\")\n",
    "# Regroupement par individu (SK_ID_CURR)\n",
    "bureau_merged = bureau_merged.groupby(\"SK_ID_CURR\").agg({\n",
    "    \"max_delay\": \"max\",          # Max retard\n",
    "    \"avg_delay\": \"mean\",         # Moyenne retard\n",
    "    \"unpaid_ratio\": \"mean\",      # Moyenne ratio impayés\n",
    "    \"DAYS_CREDIT\": \"min\",        # Premier crédit enregistré\n",
    "    \"DAYS_CREDIT_ENDDATE\": \"max\", # Dernière date de fin\n",
    "    \"DAYS_CREDIT_UPDATE\": \"max\",  # Dernière mise à jour\n",
    "    \"AMT_CREDIT_SUM\": \"sum\",      # Total crédits\n",
    "    \"AMT_CREDIT_SUM_DEBT\": \"sum\", # Total dettes\n",
    "}).reset_index()\n",
    "\n",
    "# Sauvegarde du fichier final\n",
    "bureau_merged.to_csv(\"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/merged_top_6_bureau_and_balance.csv\", index=False)\n",
    "\n",
    "print(\"Regroupement terminé et fichier enregistré ! ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de features sélectionnées : 33\n",
      "                                      Feature  Importance  \\\n",
      "27                               EXT_SOURCE_2    0.066541   \n",
      "28                               EXT_SOURCE_3    0.059268   \n",
      "7                                  DAYS_BIRTH    0.048116   \n",
      "10                            DAYS_ID_PUBLISH    0.047254   \n",
      "9                           DAYS_REGISTRATION    0.046861   \n",
      "0                                  SK_ID_CURR    0.045575   \n",
      "4                                 AMT_ANNUITY    0.043526   \n",
      "33                     DAYS_LAST_PHONE_CHANGE    0.042056   \n",
      "8                               DAYS_EMPLOYED    0.041069   \n",
      "3                                  AMT_CREDIT    0.040618   \n",
      "2                            AMT_INCOME_TOTAL    0.036131   \n",
      "6                  REGION_POPULATION_RELATIVE    0.035736   \n",
      "5                             AMT_GOODS_PRICE    0.034991   \n",
      "20                    HOUR_APPR_PROCESS_START    0.031963   \n",
      "59                 AMT_REQ_CREDIT_BUREAU_YEAR    0.021795   \n",
      "29                   OBS_30_CNT_SOCIAL_CIRCLE    0.017810   \n",
      "31                   OBS_60_CNT_SOCIAL_CIRCLE    0.017734   \n",
      "17                            CNT_FAM_MEMBERS    0.013969   \n",
      "1                                CNT_CHILDREN    0.010215   \n",
      "58                  AMT_REQ_CREDIT_BUREAU_QRT    0.009629   \n",
      "57                  AMT_REQ_CREDIT_BUREAU_MON    0.008981   \n",
      "64                          FLAG_OWN_REALTY_Y    0.007652   \n",
      "63                             FLAG_OWN_CAR_Y    0.007020   \n",
      "15                                 FLAG_PHONE    0.006972   \n",
      "82                 NAME_FAMILY_STATUS_Married    0.006854   \n",
      "30                   DEF_30_CNT_SOCIAL_CIRCLE    0.006661   \n",
      "102  ORGANIZATION_TYPE_Business Entity Type 3    0.006625   \n",
      "61                              CODE_GENDER_M    0.006467   \n",
      "96         WEEKDAY_APPR_PROCESS_START_TUESDAY    0.006425   \n",
      "19                REGION_RATING_CLIENT_W_CITY    0.006341   \n",
      "13                            FLAG_WORK_PHONE    0.006273   \n",
      "97       WEEKDAY_APPR_PROCESS_START_WEDNESDAY    0.006269   \n",
      "95        WEEKDAY_APPR_PROCESS_START_THURSDAY    0.006236   \n",
      "\n",
      "     Cumulative_Importance  \n",
      "27                0.066541  \n",
      "28                0.125809  \n",
      "7                 0.173925  \n",
      "10                0.221179  \n",
      "9                 0.268040  \n",
      "0                 0.313615  \n",
      "4                 0.357141  \n",
      "33                0.399198  \n",
      "8                 0.440267  \n",
      "3                 0.480885  \n",
      "2                 0.517015  \n",
      "6                 0.552751  \n",
      "5                 0.587742  \n",
      "20                0.619706  \n",
      "59                0.641500  \n",
      "29                0.659311  \n",
      "31                0.677044  \n",
      "17                0.691013  \n",
      "1                 0.701228  \n",
      "58                0.710857  \n",
      "57                0.719838  \n",
      "64                0.727491  \n",
      "63                0.734511  \n",
      "15                0.741483  \n",
      "82                0.748336  \n",
      "30                0.754997  \n",
      "102               0.761623  \n",
      "61                0.768089  \n",
      "96                0.774514  \n",
      "19                0.780855  \n",
      "13                0.787129  \n",
      "97                0.793398  \n",
      "95                0.799633  \n",
      "Les fichiers ont été sauvegardés :\n",
      "- 'application_train_selected.csv'\n",
      "- 'application_test_selected.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Charger les données\n",
    "application_train = df_cleaned\n",
    "application_test = pd.read_csv(\"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/application_test.csv\")\n",
    "\n",
    "# Identifier les colonnes catégorielles\n",
    "categorical_cols = application_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Appliquer le One-Hot Encoding aux variables catégorielles\n",
    "application_train_encoded = pd.get_dummies(application_train, columns=categorical_cols, drop_first=True)\n",
    "application_test_encoded = pd.get_dummies(application_test, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Vérifier si les deux jeux de données ont les mêmes colonnes après l'encodage\n",
    "# Si des colonnes sont manquantes dans l'un des datasets, il faut les aligner\n",
    "application_train_encoded, application_test_encoded = application_train_encoded.align(application_test_encoded, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Séparer les caractéristiques (X) et la cible (y) dans application_train\n",
    "X = application_train_encoded.drop(columns=[\"TARGET\"])  # On enlève la cible\n",
    "y = application_train_encoded[\"TARGET\"]  # La cible\n",
    "\n",
    "# Créer un modèle Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Afficher l'importance des features\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Créer un DataFrame pour afficher les importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Trier les importances par ordre décroissant\n",
    "importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Calculer l'importance cumulative\n",
    "importance_df['Cumulative_Importance'] = importance_df['Importance'].cumsum()\n",
    "\n",
    "# Définir le seuil d'importance cumulative (ici 80%)\n",
    "threshold = 0.80\n",
    "\n",
    "# Sélectionner les features qui atteignent ou dépassent le seuil\n",
    "selected_features = importance_df[importance_df['Cumulative_Importance'] <= threshold]\n",
    "\n",
    "# Afficher les features sélectionnées et leur importance cumulative\n",
    "print(f\"Nombre de features sélectionnées : {len(selected_features)}\")\n",
    "print(selected_features)\n",
    "\n",
    "# Sélectionner les features à garder (en excluant SK_ID_CURR)\n",
    "top_features = selected_features['Feature'].tolist()\n",
    "\n",
    "# Filtrer application_train avec les features sélectionnées\n",
    "application_train_selected = application_train_encoded[['SK_ID_CURR', 'TARGET'] + top_features]\n",
    "application_train_selected.to_csv(\"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/application_train_selected.csv\", index=False)\n",
    "\n",
    "# Filtrer application_test avec les features sélectionnées (en conservant SK_ID_CURR)\n",
    "application_test_selected = application_test_encoded[['SK_ID_CURR'] + top_features]\n",
    "application_test_selected.to_csv(\"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/application_test_selected.csv\", index=False)\n",
    "\n",
    "print(\"Les fichiers ont été sauvegardés :\")\n",
    "print(\"- 'application_train_selected.csv'\")\n",
    "print(\"- 'application_test_selected.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge de Application Train (réduit) et Bureau (et bureau balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion terminée avec uniquement les SK_ID_CURR communs. ✅\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Charger les fichiers\n",
    "application_train_selected = pd.read_csv(\n",
    "    \"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/application_train_selected.csv\"\n",
    ")\n",
    "merged_top_6_bureau_and_balance = pd.read_csv(\n",
    "    \"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/merged_top_6_bureau_and_balance.csv\"\n",
    ")\n",
    "\n",
    "# Trouver l'intersection des SK_ID_CURR\n",
    "common_ids = set(application_train_selected[\"SK_ID_CURR\"]) & set(merged_top_6_bureau_and_balance[\"SK_ID_CURR\"])\n",
    "\n",
    "# Filtrer les deux DataFrames pour ne garder que les ID communs\n",
    "application_train_selected_filtered = application_train_selected[application_train_selected[\"SK_ID_CURR\"].isin(common_ids)]\n",
    "merged_top_6_filtered = merged_top_6_bureau_and_balance[merged_top_6_bureau_and_balance[\"SK_ID_CURR\"].isin(common_ids)]\n",
    "\n",
    "# Fusionner uniquement sur les IDs communs\n",
    "application_train_gauche = application_train_selected_filtered.merge(merged_top_6_filtered, on=\"SK_ID_CURR\", how=\"inner\")\n",
    "\n",
    "# Enregistrer le fichier final\n",
    "application_train_gauche.to_csv(\n",
    "    \"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/application_train_gauche.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Fusion terminée avec uniquement les SK_ID_CURR communs. ✅\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merge de Application Test et Bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion terminée avec uniquement les SK_ID_CURR communs. ✅\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les fichiers\n",
    "application_test_selected = pd.read_csv(\n",
    "    \"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/application_test_selected.csv\"\n",
    ")\n",
    "merged_top_6_bureau_and_balance = pd.read_csv(\n",
    "    \"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/merged_top_6_bureau_and_balance.csv\"\n",
    ")\n",
    "\n",
    "# Trouver l'intersection des SK_ID_CURR\n",
    "common_ids = set(application_test_selected[\"SK_ID_CURR\"]) & set(merged_top_6_bureau_and_balance[\"SK_ID_CURR\"])\n",
    "\n",
    "# Filtrer les deux DataFrames pour ne garder que les ID communs\n",
    "application_test_selected_filtered = application_test_selected[application_test_selected[\"SK_ID_CURR\"].isin(common_ids)]\n",
    "merged_top_6_filtered = merged_top_6_bureau_and_balance[merged_top_6_bureau_and_balance[\"SK_ID_CURR\"].isin(common_ids)]\n",
    "\n",
    "# Fusionner uniquement sur les IDs communs\n",
    "application_test_gauche = application_test_selected_filtered.merge(merged_top_6_filtered, on=\"SK_ID_CURR\", how=\"inner\")\n",
    "\n",
    "# Enregistrer le fichier final\n",
    "application_test_gauche.to_csv(\n",
    "    \"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/application_test_gauche.csv\",\n",
    "    index=True\n",
    ")\n",
    "\n",
    "print(\"Fusion terminée avec uniquement les SK_ID_CURR communs. ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion terminée avec uniquement les SK_ID_CURR communs. ✅\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les fichiers\n",
    "final_application_droite = pd.read_csv(\n",
    "    \"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/final_application_data2.csv\"\n",
    ")\n",
    "application_train_gauche = pd.read_csv(\n",
    "    \"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/application_train_gauche.csv\"\n",
    ")\n",
    "\n",
    "# Trouver l'intersection des SK_ID_CURR\n",
    "common_ids = set(final_application_droite[\"SK_ID_CURR\"]) & set(application_train_gauche[\"SK_ID_CURR\"])\n",
    "\n",
    "# Filtrer les deux DataFrames pour ne garder que les ID communs\n",
    "final_application_droite_filtered = final_application_droite[final_application_droite[\"SK_ID_CURR\"].isin(common_ids)]\n",
    "application_train_gauche_filtered = application_train_gauche[application_train_gauche[\"SK_ID_CURR\"].isin(common_ids)]\n",
    "\n",
    "# Fusionner uniquement sur les IDs communs\n",
    "final_application_train = final_application_droite_filtered.merge(application_train_gauche_filtered, on=\"SK_ID_CURR\", how=\"inner\")\n",
    "\n",
    "# Enregistrer le fichier final\n",
    "final_application_train.to_csv(\n",
    "    \"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/final_application_train.csv\",\n",
    "    index=True\n",
    ")\n",
    "\n",
    "print(\"Fusion terminée avec uniquement les SK_ID_CURR communs. ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion terminée avec uniquement les SK_ID_CURR communs. ✅\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les fichiers\n",
    "final_application_droite = pd.read_csv(\n",
    "    \"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/final_application_data2.csv\"\n",
    ")\n",
    "application_test_gauche = pd.read_csv(\n",
    "    \"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/application_test_gauche.csv\"\n",
    ")\n",
    "\n",
    "# Trouver l'intersection des SK_ID_CURR\n",
    "common_ids = set(final_application_droite[\"SK_ID_CURR\"]) & set(application_test_gauche[\"SK_ID_CURR\"])\n",
    "\n",
    "# Filtrer les deux DataFrames pour ne garder que les ID communs\n",
    "final_application_droite_filtered = final_application_droite[final_application_droite[\"SK_ID_CURR\"].isin(common_ids)]\n",
    "application_test_gauche_filtered = application_test_gauche[application_test_gauche[\"SK_ID_CURR\"].isin(common_ids)]\n",
    "\n",
    "# Fusionner uniquement sur les IDs communs\n",
    "final_application_test = final_application_droite_filtered.merge(application_test_gauche_filtered, on=\"SK_ID_CURR\", how=\"inner\")\n",
    "\n",
    "# Enregistrer le fichier final\n",
    "final_application_test.to_csv(\n",
    "    \"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/final_application_test.csv\",\n",
    "    index=True\n",
    ")\n",
    "\n",
    "print(\"Fusion terminée avec uniquement les SK_ID_CURR communs. ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'ID présents dans final_application_data2.csv mais absents de application_train.csv : 47800\n",
      "Exemples d'ID manquants dans application_train.csv : [131072, 393216, 393218, 262152, 393224, 393227, 131084, 262159, 131088, 131089]\n",
      "Nombre d'ID présents dans application_train.csv mais absents de final_application_data2.csv : 16454\n",
      "Exemples d'ID manquants dans final_application_data2.csv : [163842, 163846, 229383, 262151, 196617, 360455, 425990, 294929, 163858, 229394]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les fichiers\n",
    "file1 = \"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/final_application_data2.csv\"\n",
    "file2 = \"/Users/konstantinganz/Library/CloudStorage/OneDrive-Personnel/Documents/Konstantin/CS/S8 Hong Kong/Cours/Stat ML/Projet_1/kaggle_statml_housing_credit/data/home-credit-default-risk/application_train.csv\"\n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "# Convertir SK_ID_CURR en set\n",
    "ids1 = set(df1[\"SK_ID_CURR\"])\n",
    "ids2 = set(df2[\"SK_ID_CURR\"])\n",
    "\n",
    "# Vérifier les IDs manquants\n",
    "missing_in_file2 = ids1 - ids2\n",
    "missing_in_file1 = ids2 - ids1\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"Nombre d'ID présents dans final_application_data2.csv mais absents de application_train.csv : {len(missing_in_file2)}\")\n",
    "if missing_in_file2:\n",
    "    print(\"Exemples d'ID manquants dans application_train.csv :\", list(missing_in_file2)[:10])\n",
    "\n",
    "print(f\"Nombre d'ID présents dans application_train.csv mais absents de final_application_data2.csv : {len(missing_in_file1)}\")\n",
    "if missing_in_file1:\n",
    "    print(\"Exemples d'ID manquants dans final_application_data2.csv :\", list(missing_in_file1)[:10])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
